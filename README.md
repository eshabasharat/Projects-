# Projects/Assignments 
Project_Proposal: Canadian Brewhouse 
DATA 3960 – Canadian Brewhouse Project Proposal

Goal: Improve customer retention at the Canadian Brewhouse by analyzing factors that impact customer loyalty, focusing on rewards programs, promotions, and personalized offers.

Guest_NAIT: Tracks customer check-ins, loyalty points, and signup channels.
User_Feedback_NAIT: Provides customer feedback and satisfaction insights.
Analysis Objectives:

Determine if rewards increase visit frequency and spending.
Assess effectiveness of promotions like Game Days.
Explore how personalized offers affect loyalty.
Technical Approach:

Clean and organize datasets.
Use regression models for retention prediction.
Create visualizations in Power BI.
Project Timeline: ~12 weeks with key deadlines:

Mid-Point Presentation: March 5
Final Presentation: April 23


Mid_Point_Documentaion: Canadian Brewhouse 
Canadian Brewhouse Customer Retention Project – Mid-Point Documentation

Group Members: Esha Basharat, Tsz Fung Cheung, Michael Harris, Kurtis Li

Objective: Improve customer retention for Canadian Brewhouse by enhancing loyalty and referral programs, optimizing promotions, and analyzing customer feedback to increase repeat visits and engagement.

Key Insights:

Top Location: Lewis Estates is the most popular, indicating strong engagement at this site.
Sign-Up Channel Impact: Mobile/email channels account for over 63% of check-ins, highlighting digital engagement's importance.
Customer Feedback: Positive and negative keywords reveal areas of customer satisfaction and needed improvements.
Research Questions:

Do higher rewards increase customer visits and spending?
Does positive feedback correlate with retention?
Do special events (e.g., game days) boost check-ins?
Does reward redemption drive loyalty?
Is the referral program attracting new customers?
Methods:

Data Cleaning: Addressing missing values and irrelevant data using Python.
Analysis: Using Power BI for visualization and Python for predictive modeling to find trends in check-ins, redemptions, and referrals.
Challenges: Initial data transformation issues resolved through consistent standards across platforms.

Next Steps: Expand modeling to analyze retention strategies, comparing loyalty and referral program effectiveness for actionable recommendations.


Final_Documentation: Canadian Brewhouse 
Improving Customer Retention at The Canadian Brewhouse

Group: Esha Basharat, Tsz Fung Cheung, Michael Harris, Kurtis Li
Institution: Northern Alberta Institute of Technology, DATA 3960 Capstone Project
Date: April 23, 2024

Summary:
This project focuses on increasing customer retention at The Canadian Brewhouse by analyzing data from their loyalty app program. Using data on check-ins, guest info, feedback, referrals, and redemptions, we identified high-value customer segments and engagement trends, providing insights for targeted marketing and loyalty strategies.

Key Findings and Recommendations:

Customer Segmentation: LRFM analysis identified loyalty levels, aiding targeted campaigns for high-value customers.
Boost Loyalty Program Engagement: Highlight top rewards, tailor events (e.g., sports game days and craft beer nights), and incentivize referrals.
Location-Specific Promotions: Customize promotions based on popular locations and customer feedback.
VIP Program: Implement a tiered loyalty program for top-spending customers to drive engagement.
Conclusion:
Optimizing customer engagement through data-driven strategies will strengthen loyalty and support long-term growth at The Canadian Brewhouse.


Assignment1_GroupD:
Building a Data Analytics Strategic Goal: Managing Expired Products in Retail

Group D: Esha Basharat, Jean Louise Encenarial, Neha Sharma, Vaibhavikumari Tailor

Project Overview

This project addresses the issue of expired products on the shelves of retail stores, using Walmart as a case study. Our goal is to develop a data-driven strategy to reduce expired products through enhanced employee training, inventory management, and communication.

Key Components
Problem Analysis: Identified root causes of expired products on shelves, such as inadequate training, miscommunication, labor division inefficiencies, and overstock.
Forcefield Analysis: Analyzed positive and negative forces affecting the removal of expired products.
Strategic Goals: Established SMART goals to improve expiry checks, organize inventory, and enhance communication.
Proposed Solutions: Recommended consistent training, incentives, markdown strategies, and data analytics for inventory tracking.
Objectives
SMART Goal: Check all expiry dates twice monthly to prevent expired products from remaining on shelves.
Long-term Impact: Reduce waste, increase customer satisfaction, and improve inventory management through a standardized approach.
This strategy aims to create a sustainable model for managing product expiry, benefiting both the business and its customers.


Assignment2_GroupD:
Increasing House Flipping Profits in Seattle, WA

This project outlines a data-driven strategy for house flipping in Seattle’s competitive housing market, focusing on maximizing property value, targeting high-demand locations, and increasing housing capacity in desirable neighborhoods.

Key Components

Market Analysis: Assesses high-demand areas like Ballard and other neighborhoods with redevelopment potential, analyzing proximity to amenities, accessibility, and community appeal.
Addressing Inventory Constraints: Proposes strategies such as redevelopment of older properties on larger lots to optimize housing supply and enhance property values.
Data-Driven Insights:
Floor Space and Property Grade: Establishes that larger living spaces and property grade are primary drivers of home value, supported by correlation data and predictive models (XGB Regressor, Decision Tree).
Bedrooms and Bathrooms: Examines how the number of bedrooms and bathrooms affects property value, highlighting their appeal to specific buyer demographics.
Practical Execution: Emphasizes close collaboration with architectural experts, adherence to zoning laws, and the use of predictive analytics to optimize property selection, renovation, and market timing.
Conclusion

Our strategy harnesses Seattle’s high housing demand, focuses on strategic redevelopment, and maximizes profits through a systematic approach to property selection and enhancement. This report serves as a roadmap to success in Seattle’s real estate market, aligning financial gains with sustainable urban growth.


Data_Ecosystem_Report:
Optimizing Data Ecosystems for Business Efficiency

This project investigates how businesses create effective data ecosystems to manage and leverage data effectively.

Key Sections

Data Ecosystems:
Collaborative networks that link data sources, enhancing accessibility and efficiency across businesses.
Data Pipelines and Lakes:
Pipelines: Transform raw data into usable insights, integrating information across systems.
Lakes: Centralized storage hubs for raw data, supporting advanced analytics and data accessibility.
Data Management Systems:
Analysis of three platforms:
Teradata: Reliable and scalable.
Snowflake: Flexible, cloud-based with data lake/warehouse integration.
Databricks: Unified data lakehouse for AI-driven insights.
Case Study: AMN Healthcare:
Transitioning to Snowflake reduced costs and complexity for AMN, highlighting the impact of streamlined data management.
Conclusion

Modern businesses rely on data ecosystems to improve data quality, reduce costs, and enhance decision-making. This report offers a roadmap for building effective data frameworks.


ML_Assignment (Tree based models):
Tree-Based Classification Model - Assignment 3950 Part 2

This project builds a tree-based classification model to analyze a dataset, focusing on avoiding overfitting with a small training set. Key components include data preprocessing, model training, and evaluation.

Project Overview

Data Preprocessing: A pipeline preprocesses data by scaling features and supports seamless transformation for both training and test sets.
Modeling: Utilizes a RandomForestClassifier as the tree-based model, with hyperparameter tuning through GridSearchCV to optimize accuracy.
Evaluation: Metrics such as accuracy and ROC-AUC are used to assess model performance.
Key Features

Pipeline for Data Transformation: Streamlines data prep and model integration.
Hyperparameter Tuning: Uses grid search to refine model performance.
Configurable EDA: Allows optional exploratory data analysis visualization.
To run the model on test data, set the best-performing model as best, ensuring easy scoring across different datasets


ML_Assignment:
Tree-Based Classification Model - Assignment 3950 Part 2

This project classifies data using a tree-based model with a focus on avoiding overfitting due to a small training set.

Overview

Pipeline Setup: Preprocesses and scales data within a pipeline.
Tree Model: Utilizes RandomForestClassifier with hyperparameter tuning via GridSearchCV.
Metrics: Evaluates accuracy and ROC-AUC to assess model performance.
Key Steps

Data Preparation: Pipeline scales features for training and testing.
Hyperparameter Tuning: Optimizes model accuracy.
Evaluation: Calculates accuracy on test data using the best model.
The final model is stored in best for easy testing and evaluation.


ML_Project_2:
Project 2 - Vegetable Classification

This project uses a Convolutional Neural Network (CNN) to classify images of vegetables into 15 different classes.

Overview

Data Preparation: Downloads, unzips, and preprocesses the image dataset. The images are resized and loaded into training, validation, and test datasets.
Model Architecture: Builds a CNN model with convolutional, pooling, and dense layers for image classification.
Training: Trains the model on the training dataset with early stopping to prevent overfitting. Hyperparameters such as batch size and learning rate are tuned for optimal performance.
Evaluation: Tests the model’s accuracy on the test dataset and generates metrics like accuracy, precision, recall, and confusion matrix.
Results

The model achieves approximately 73.9% accuracy on the test dataset. Performance metrics are visualized using plots and a confusion matrix.


Machine_Learning_Project:
Project 1 - NLP Text Classification

This project uses Natural Language Processing (NLP) to classify comments into multiple toxicity categories.

Overview

Data Preparation: Loads and preprocesses the dataset. A subset is used to reduce computational time, and common NLP tasks like stopword removal and tokenization are applied.
Modeling: A Support Vector Machine (SVM) is trained separately for each toxicity class (e.g., toxic, severe toxic, obscene) using TfidfVectorizer for text representation.
Evaluation: Each model’s accuracy is evaluated on a test split, achieving over 93% accuracy on most classes.
Prediction: Trained models predict toxicity categories for new data, and results are compiled into a final CSV file.


Python_3:
Python Scripts for Basic Computational Tasks

This repository includes multiple Python scripts, each designed to perform specific tasks involving loops, conditionals, and user input handling. Below is an overview of each script’s functionality.

Script Descriptions

Sum of Odd Numbers:
Prompts the user to enter two integers, a and b, and calculates the sum of all odd numbers between these values (inclusive).
Displays the result with clear formatting.
Vowel Replacer:
Accepts a user-inputted string and replaces all vowels with underscores (_).
Outputs the modified string.
Investment Growth Calculator:
Takes an initial balance and interest rate as input, then calculates the number of years required for the investment to triple.
Displays the result, showing the years needed based on the given interest rate.
Includes error handling for valid numeric inputs.
Prime Factorization:
Asks the user for an integer and calculates its prime factors.
Displays the factors if they exist, or identifies the number as prime if no factors are found.
Grade Counter:
Collects grades from the user until -1 is entered to stop.
Counts and displays the number of passing (grades >= 50) and failing grades (grades < 50).

Each script handles errors gracefully, ensuring a smooth experience with informative prompts and outputs.


Python_4:
Python Utilities - Various Operations

This project includes several Python scripts, each performing a distinct operation. These scripts demonstrate core programming concepts such as list manipulation, dictionary usage, user input handling, and data validation. Below is a description of each section:

Script Descriptions

Rider Line Manager:
Implements a line management system for riders, allowing for standard and VIP entries.
Includes options to add riders, add VIPs, dispatch riders, display the line, and exit.
Unique Numbers Collector:
Collects unique numbers from the user until ten unique numbers are entered.
Ensures no duplicates and provides real-time feedback on the current list of unique entries.
Die Toss Frequency Counter:
Tracks the frequency of each result from a 12-sided die toss.
Accepts results from 1 to 12 and displays the frequency of each outcome when the user quits.
List Halves Switcher:
Switches the first and second halves of a list if the list length is even.
Returns an error message if the list length is odd.
Filter Integers within Range:
Filters integers from a list based on a user-specified lower and upper bound.
Displays the integers that fall within the specified range.
Acronym Generator:
Creates an acronym from a user-inputted phrase by taking the first uppercase letter from each word.
Compare Characters in Strings:
Compares two strings to find characters that are common between them and characters unique to each string.

Each function includes error handling and feedback, making it user-friendly and robust.


Python_5:
Python Utilities - Various Functions

This assignment includes several Python functions, each designed to perform specific tasks. Each function demonstrates a different aspect of programming, including file handling, string manipulation, and input validation. Below is a description of each function:

Function Descriptions

BMI Calculator:
Prompts the user for weight (in kilograms) and height (in meters) to calculate the Body Mass Index (BMI).
Provides health advice based on the calculated BMI.
Includes error handling for invalid inputs and zero height values.
DataFrame Display:
Uses pandas to read and display data from a CSV file (Lab5_input.txt), showing basic DataFrame handling.
Search Words in Range:
Reads words from a specified file and prints those within a specified alphabetical range.
Demonstrates file handling and string filtering within defined bounds.
Includes error handling for file-related issues.
Acronym Generator:
Generates an acronym from a given phrase by taking the uppercase initials of each word.
Illustrates string manipulation and looping.
Compare Strings:
Compares two strings to identify characters that are common between them and characters unique to each.
Demonstrates set operations for finding intersections and symmetric differences.
Each function includes sample usage to illustrate its functionality and the expected output, making it straightforward to test and adapt to other projects.


Python_6:
Python Classes and Objects - Assignment

This assignment contains several Python classes, each designed to demonstrate basic object-oriented programming concepts like encapsulation, attribute management, and methods. Each class serves a different purpose, providing unique functionalities. Below is a brief description of each class:

Class Descriptions
PatientData: Stores and displays patient height and weight before and after updating with new values.
InventoryTag: Represents an inventory item with a unique tag ID and quantity.
Car: Calculates and displays the current value of a car based on its model year, purchase price, and depreciation rate.
Address: Stores and displays a mailing address, with support for optional apartment numbers.
Triangle: Manages a triangle's base and height, calculates its area, and determines which triangle has a larger area when comparing two instances.
Each class includes sample usage code to demonstrate its functionality and expected output, making it easy to understand and test.
